{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64e14176",
   "metadata": {},
   "source": [
    "# Task 1: Data Collection - TechnoHacks Internship\n",
    "\n",
    "## üéØ Objective:\n",
    "To collect a real-world dataset from an open-source source (UCI Machine Learning Repository), load it using Python, explore it briefly, and save it in a structured format (CSV).\n",
    "\n",
    "## üìå Dataset Chosen:\n",
    "**Iris Dataset** from UCI Machine Learning Repository\n",
    "\n",
    "## üìã Description:\n",
    "The Iris dataset is a classic dataset in machine learning that contains measurements of 150 iris flowers from three species: Iris setosa, Iris versicolor, and Iris virginica. Each sample has four features:\n",
    "\n",
    "- **Sepal Length**\n",
    "- **Sepal Width**\n",
    "- **Petal Length**\n",
    "- **Petal Width**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05437937",
   "metadata": {},
   "source": [
    "## üîπ 1. Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "026bf873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ded5f1a",
   "metadata": {},
   "source": [
    "## üîπ 2. Loading the Dataset\n",
    "\n",
    "Since we're working offline, we'll load the dataset from the local CSV file that was previously downloaded from the UCI repository:\n",
    "\n",
    "Original URL: `https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3aa5e282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Shape of the dataset: (150, 5)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('iris_dataset.csv')\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"Shape of the dataset: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99a418a",
   "metadata": {},
   "source": [
    "## üîπ 3. Displaying First Few Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d785837b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "   sepal_length  sepal_width  petal_length  petal_width        class\n",
      "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
      "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
      "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
      "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
      "4           5.0          3.6           1.4          0.2  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde060b2",
   "metadata": {},
   "source": [
    "## üîπ 4. Dataset Information and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "449303ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   class         150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Basic information about the dataset\n",
    "print(\"Dataset Information:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1c1fb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistical Summary:\n",
      "       sepal_length  sepal_width  petal_length  petal_width\n",
      "count    150.000000   150.000000    150.000000   150.000000\n",
      "mean       5.843333     3.054000      3.758667     1.198667\n",
      "std        0.828066     0.433594      1.764420     0.763161\n",
      "min        4.300000     2.000000      1.000000     0.100000\n",
      "25%        5.100000     2.800000      1.600000     0.300000\n",
      "50%        5.800000     3.000000      4.350000     1.300000\n",
      "75%        6.400000     3.300000      5.100000     1.800000\n",
      "max        7.900000     4.400000      6.900000     2.500000\n"
     ]
    }
   ],
   "source": [
    "# Statistical summary\n",
    "print(\"\\nStatistical Summary:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4885934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values:\n",
      "sepal_length    0\n",
      "sepal_width     0\n",
      "petal_length    0\n",
      "petal_width     0\n",
      "class           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "734eb2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique Classes:\n",
      "class\n",
      "Iris-setosa        50\n",
      "Iris-versicolor    50\n",
      "Iris-virginica     50\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check unique classes\n",
    "print(\"\\nUnique Classes:\")\n",
    "print(df['class'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aec1d2",
   "metadata": {},
   "source": [
    "## üîπ 5. Data Validation and Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d05b9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types:\n",
      "sepal_length    float64\n",
      "sepal_width     float64\n",
      "petal_length    float64\n",
      "petal_width     float64\n",
      "class            object\n",
      "dtype: object\n",
      "\n",
      "Duplicate rows: 3\n",
      "\n",
      "Column names: ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n"
     ]
    }
   ],
   "source": [
    "# Check data types\n",
    "print(\"Data Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Check for any duplicate rows\n",
    "print(f\"\\nDuplicate rows: {df.duplicated().sum()}\")\n",
    "\n",
    "# Display column names\n",
    "print(f\"\\nColumn names: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2661cab",
   "metadata": {},
   "source": [
    "## üîπ 6. Final Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6976295d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FINAL DATASET OVERVIEW ===\n",
      "Total samples: 150\n",
      "Total features: 4\n",
      "Classes: 3\n",
      "Missing values: 0\n",
      "\n",
      "Dataset is ready for further analysis!\n"
     ]
    }
   ],
   "source": [
    "print(\"=== FINAL DATASET OVERVIEW ===\")\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Total features: {len(df.columns) - 1}\")\n",
    "print(f\"Classes: {df['class'].nunique()}\")\n",
    "print(f\"Missing values: {df.isnull().sum().sum()}\")\n",
    "print(\"\\nDataset is ready for further analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6151f17a",
   "metadata": {},
   "source": [
    "## üîπ 7. Saving Dataset as CSV\n",
    "\n",
    "The dataset is already in CSV format and ready for future use in data cleaning, visualization, or modeling tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2eb688f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset saved successfully as 'iris_dataset.csv'\n",
      "\n",
      "The dataset is now ready for:\n",
      "- Data Cleaning (Task 2)\n",
      "- Data Visualization (Task 3)\n",
      "- Machine Learning Modeling (Task 4)\n"
     ]
    }
   ],
   "source": [
    "# Save the dataset (confirmation)\n",
    "df.to_csv(\"iris_dataset.csv\", index=False)\n",
    "print(\"‚úÖ Dataset saved successfully as 'iris_dataset.csv'\")\n",
    "print(\"\\nThe dataset is now ready for:\")\n",
    "print(\"- Data Cleaning (Task 2)\")\n",
    "print(\"- Data Visualization (Task 3)\")\n",
    "print(\"- Machine Learning Modeling (Task 4)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e3b1be",
   "metadata": {},
   "source": [
    "## üìÅ Files Created:\n",
    "- `iris_dataset.csv` ‚Äì Complete Iris dataset ready for analysis\n",
    "- `Task1_DataCollection.ipynb` ‚Äì This notebook with all steps and outputs\n",
    "\n",
    "## üìå Summary:\n",
    "‚úÖ **Task 1 Completed Successfully!**\n",
    "\n",
    "In this task, we:\n",
    "1. ‚úÖ Collected a real-world dataset from UCI Machine Learning Repository\n",
    "2. ‚úÖ Loaded the dataset using Python and Pandas\n",
    "3. ‚úÖ Explored the dataset structure and characteristics\n",
    "4. ‚úÖ Validated data quality (no missing values, no duplicates)\n",
    "5. ‚úÖ Saved the dataset in structured CSV format\n",
    "\n",
    "The Iris dataset is now ready for the next phases of the data science pipeline!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
